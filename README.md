# BioLearn-GPT: Generador de Contenido Educativo en BioingenierÃ­a

## ğŸ§¬ DescripciÃ³n del Proyecto

BioLearn-GPT es un sistema avanzado de generaciÃ³n de contenido educativo basado en inteligencia artificial, especÃ­ficamente diseÃ±ado para crear explicaciones adaptativas sobre conceptos de bioingenierÃ­a y fisiologÃ­a. El proyecto utiliza tÃ©cnicas de fine-tuning de modelos de lenguaje (GPT-2) para generar explicaciones personalizadas segÃºn el nivel de conocimiento del usuario.

### ğŸ¯ Objetivos

- **Objetivo General**: Desarrollar un sistema basado en modelos Transformer capaz de generar explicaciones coherentes y factualmente precisas sobre conceptos complejos de bioingenierÃ­a y fisiologÃ­a, adaptando el nivel de detalle al conocimiento previo del usuario.

- **Objetivos EspecÃ­ficos**:
  1. Recopilar y curar un dataset de textos educativos sobre bioingenierÃ­a
  2. Implementar un sistema de etiquetado por niveles de dificultad
  3. Realizar fine-tuning de un modelo GPT-2 en espaÃ±ol
  4. Desarrollar un mecanismo de prompting condicional
  5. Evaluar el modelo cuantitativa y cualitativamente

## ğŸš€ CaracterÃ­sticas Principales

- **GeneraciÃ³n Adaptativa**: Produce explicaciones en tres niveles de dificultad (Principiante, Intermedio, Experto)
- **Dominio EspecÃ­fico**: Especializado en bioingenierÃ­a y fisiologÃ­a
- **Interfaz Web**: Interfaz intuitiva desarrollada con Gradio
- **Pipeline Completo**: Desde scraping de datos hasta evaluaciÃ³n del modelo
- **EvaluaciÃ³n Exhaustiva**: MÃ©tricas cuantitativas y cualitativas

## ğŸ“ Estructura del Proyecto

```
BioGPT/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ main.py                 # Pipeline principal
â”‚   â”œâ”€â”€ config.py              # Configuraciones del proyecto
â”‚   â”œâ”€â”€ web_scraper.py         # Scraping de datos educativos
â”‚   â”œâ”€â”€ data_processor.py      # Procesamiento y limpieza de datos
â”‚   â”œâ”€â”€ model_trainer.py       # Entrenamiento del modelo
â”‚   â”œâ”€â”€ model_evaluator.py     # EvaluaciÃ³n del modelo
â”‚   â””â”€â”€ gradio_app.py          # Interfaz web
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ scraped_data/          # Datos recopilados
â”‚   â””â”€â”€ processed/             # Datos procesados para entrenamiento
â”œâ”€â”€ biogpt_model/              # Modelo entrenado
â”œâ”€â”€ requirements.txt           # Dependencias
â””â”€â”€ README.md                  # Este archivo
```

## ğŸ› ï¸ InstalaciÃ³n y ConfiguraciÃ³n

### Requisitos Previos

- Python 3.8+
- GPU recomendada (opcional, pero acelera el entrenamiento)
- 8GB+ de RAM

### InstalaciÃ³n

1. **Clonar el repositorio**:

```bash
git clone <repository-url>
cd BioGPT
```

2. **Crear entorno virtual**:

```bash
python -m venv venv
source venv/bin/activate  # En Windows: venv\Scripts\activate
```

3. **Instalar dependencias**:

```bash
pip install -r requirements.txt
```

4. **Configurar NLTK** (si es necesario):

```bash
python -c "import nltk; nltk.download('punkt')"
```

## ğŸ“Š Uso del Sistema

### 1. EjecuciÃ³n del Pipeline Completo

Para ejecutar todo el pipeline desde cero:

```bash
cd src
python main.py --mode all
```

### 2. EjecuciÃ³n por Fases

**Scraping de datos**:

```bash
python main.py --mode scrape
```

**Procesamiento de datos**:

```bash
python main.py --mode process
```

**Entrenamiento del modelo**:

```bash
python main.py --mode train
```

**EvaluaciÃ³n del modelo**:

```bash
python main.py --mode evaluate
```

### 3. Interfaz Web

Lanzar la interfaz Gradio:

```bash
python gradio_app.py
```

Acceder a: `http://localhost:7860`

## ğŸ”§ ConfiguraciÃ³n Avanzada

### ParÃ¡metros del Modelo

Editar `config.py` para ajustar:

```python
@dataclass
class ModelConfig:
    base_model_name: str = "DeepESP/gpt2-spanish"
    learning_rate: float = 5e-5
    batch_size: int = 4
    num_epochs: int = 3
    max_length: int = 512
    # ... mÃ¡s parÃ¡metros
```

### ConfiguraciÃ³n de Scraping

```python
@dataclass
class ScrapingConfig:
    max_pages_per_source: int = 100
    delay_between_requests: float = 1.0
    timeout: int = 10
    # ... mÃ¡s configuraciones
```

## ğŸ“ˆ EvaluaciÃ³n y MÃ©tricas

El sistema incluye evaluaciÃ³n exhaustiva:

### MÃ©tricas Cuantitativas

- **Perplejidad**: Mide la calidad del modelo de lenguaje
- **Coherencia**: AnÃ¡lisis de fluidez textual
- **Relevancia**: Pertinencia del contenido generado
- **Completitud**: EvaluaciÃ³n de la exhaustividad

### MÃ©tricas Cualitativas

- **Consistencia de Nivel**: EvaluaciÃ³n de la adaptaciÃ³n al nivel solicitado
- **PrecisiÃ³n Factual**: VerificaciÃ³n de la exactitud cientÃ­fica
- **AdecuaciÃ³n Educativa**: EvaluaciÃ³n pedagÃ³gica del contenido

### Resultados de Ejemplo

```
Concept: cÃ©lula (Principiante)
- Avg sentence length: 12.3
- Technical terms: 2
- Estimated level: principiante
- Coherence score: 0.85
```

## ğŸ” Ejemplos de Uso

### Nivel Principiante

```
Prompt: "[PRINCIPIANTE] Explica quÃ© es una cÃ©lula"
Salida: "La cÃ©lula es la unidad mÃ¡s pequeÃ±a de la vida. Todos los seres vivos estÃ¡n formados por cÃ©lulas..."
```

### Nivel Intermedio

```
Prompt: "[INTERMEDIO] Explica la homeostasis"
Salida: "La homeostasis es el proceso mediante el cual los organismos mantienen un equilibrio interno estable..."
```

### Nivel Experto

```
Prompt: "[EXPERTO] Explica la transducciÃ³n de seÃ±ales"
Salida: "La transducciÃ³n de seÃ±ales celulares implica cascadas de fosforilaciÃ³n que regulan la expresiÃ³n gÃ©nica..."
```

## ğŸš¨ Limitaciones y Consideraciones

### Limitaciones Conocidas

1. **Alucinaciones**: El modelo puede generar informaciÃ³n incorrecta
2. **Datos Limitados**: Dependiente de la calidad del dataset de entrenamiento
3. **EvaluaciÃ³n Subjetiva**: La calidad educativa es difÃ­cil de medir objetivamente

### Mitigaciones

- CuraciÃ³n cuidadosa del dataset
- EvaluaciÃ³n humana complementaria
- Advertencias sobre verificaciÃ³n de contenido
