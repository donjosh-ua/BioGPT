#!/usr/bin/env python3
"""
Usage guide and quickstart for BioGPT project.
"""

import os
import sys


def print_header(text, char="="):
    """Print a formatted header"""
    print(f"\n{char * 60}")
    print(f"{text:^60}")
    print(f"{char * 60}")


def print_section(text, char="-"):
    """Print a formatted section header"""
    print(f"\n{char * 40}")
    print(f"{text}")
    print(f"{char * 40}")


def show_quickstart():
    """Show quickstart guide"""
    print_header("ðŸš€ BioGPT Quickstart Guide")

    print(
        """
Â¡Bienvenido a BioLearn-GPT!
Este sistema genera contenido educativo adaptativo para bioingenierÃ­a.
"""
    )

    print_section("1. InstalaciÃ³n Inicial")
    print(
        """
# Crear entorno virtual
python -m venv venv
source venv/bin/activate  # Linux/Mac
# o
venv\\Scripts\\activate     # Windows

# Instalar dependencias
pip install -r requirements.txt

# Ejecutar setup
python setup.py
"""
    )

    print_section("2. EjecuciÃ³n RÃ¡pida")
    print(
        """
# OpciÃ³n 1: Pipeline completo (recomendado para primera ejecuciÃ³n)
python src/main.py --mode all

# OpciÃ³n 2: Solo interfaz web (si ya tienes modelo entrenado)
python src/gradio_app.py

# OpciÃ³n 3: Ejecutar demo
python demo.py
"""
    )

    print_section("3. EjecuciÃ³n por Fases")
    print(
        """
# Fase 1: RecolecciÃ³n de datos
python src/main.py --mode scrape

# Fase 2: Procesamiento de datos
python src/main.py --mode process

# Fase 3: Entrenamiento del modelo
python src/main.py --mode train

# Fase 4: EvaluaciÃ³n del modelo
python src/main.py --mode evaluate
"""
    )

    print_section("4. Uso de la Interfaz Web")
    print(
        """
1. Ejecutar: python src/gradio_app.py
2. Abrir navegador en: http://localhost:7860
3. Introducir concepto (ej: "cÃ©lula", "homeostasis")
4. Seleccionar nivel (Principiante, Intermedio, Experto)
5. Hacer clic en "Generar ExplicaciÃ³n"
"""
    )


def show_detailed_usage():
    """Show detailed usage information"""
    print_header("ðŸ“– Uso Detallado del Sistema")

    print_section("ConfiguraciÃ³n Avanzada")
    print(
        """
Editar src/config.py para personalizar:

â€¢ ModelConfig: ParÃ¡metros del modelo
  - base_model_name: Modelo base a usar
  - learning_rate: Tasa de aprendizaje
  - batch_size: TamaÃ±o de lote
  - num_epochs: NÃºmero de Ã©pocas

â€¢ DataConfig: ConfiguraciÃ³n de datos
  - data_dir: Directorio de datos
  - level_tokens: Tokens de control

â€¢ ScrapingConfig: ConfiguraciÃ³n de scraping
  - max_pages_per_source: PÃ¡ginas mÃ¡ximas por fuente
  - delay_between_requests: Retraso entre peticiones
"""
    )

    print_section("Estructura de Datos")
    print(
        """
data/
â”œâ”€â”€ scraped_data/          # Datos recolectados
â”‚   â”œâ”€â”€ wikipedia_biology.csv
â”‚   â””â”€â”€ educational_sites.csv
â”œâ”€â”€ processed/             # Datos procesados
â”‚   â”œâ”€â”€ training_data.txt
â”‚   â”œâ”€â”€ validation_data.txt
â”‚   â””â”€â”€ test_data.txt
â””â”€â”€ ...

biogpt_model/              # Modelo entrenado
â”œâ”€â”€ config.json
â”œâ”€â”€ model.safetensors
â”œâ”€â”€ tokenizer.json
â”œâ”€â”€ evaluation_results.json
â””â”€â”€ sample_outputs.json
"""
    )

    print_section("Formato de Prompts")
    print(
        """
El sistema usa tokens de control para niveles:

[PRINCIPIANTE] Texto simple y accesible
[INTERMEDIO] Texto con tÃ©rminos tÃ©cnicos moderados
[EXPERTO] Texto tÃ©cnico avanzado

Ejemplo de uso:
prompt = "[PRINCIPIANTE] Explica quÃ© es una cÃ©lula"
"""
    )

    print_section("EvaluaciÃ³n del Modelo")
    print(
        """
El sistema evalÃºa:

â€¢ MÃ©tricas Cuantitativas:
  - Perplejidad
  - Coherencia textual
  - Relevancia temÃ¡tica

â€¢ MÃ©tricas Cualitativas:
  - Consistencia de nivel
  - PrecisiÃ³n factual
  - Completitud educativa

Archivos de evaluaciÃ³n:
â€¢ evaluation_results.json: MÃ©tricas numÃ©ricas
â€¢ evaluation_report.txt: Reporte legible
â€¢ sample_outputs.json: Ejemplos generados
"""
    )


def show_troubleshooting():
    """Show troubleshooting guide"""
    print_header("ðŸ”§ SoluciÃ³n de Problemas")

    problems = [
        {
            "problem": "Error al cargar el modelo",
            "solution": """
â€¢ Verificar que el modelo estÃ© entrenado:
  ls biogpt_model/
  
â€¢ Si no existe, ejecutar entrenamiento:
  python src/main.py --mode train
  
â€¢ Si persiste, usar modelo base:
  Se cargarÃ¡ automÃ¡ticamente el modelo base
""",
        },
        {
            "problem": "Datos de entrenamiento no encontrados",
            "solution": """
â€¢ Ejecutar recolecciÃ³n de datos:
  python src/main.py --mode scrape
  
â€¢ Procesar datos:
  python src/main.py --mode process
  
â€¢ Verificar archivos:
  ls data/scraped_data/
  ls data/processed/
""",
        },
        {
            "problem": "Error de memoria durante entrenamiento",
            "solution": """
â€¢ Reducir batch_size en config.py
â€¢ Aumentar gradient_accumulation_steps
â€¢ Usar modelo mÃ¡s pequeÃ±o
â€¢ Verificar RAM/VRAM disponible
""",
        },
        {
            "problem": "Interfaz Gradio no carga",
            "solution": """
â€¢ Verificar puerto disponible (7860)
â€¢ Comprobar firewall
â€¢ Usar IP especÃ­fica:
  iface.launch(server_name="0.0.0.0")
""",
        },
    ]

    for i, item in enumerate(problems, 1):
        print(f"\n{i}. {item['problem']}")
        print(f"   SoluciÃ³n:{item['solution']}")


def show_examples():
    """Show usage examples"""
    print_header("ðŸ’¡ Ejemplos de Uso")

    examples = [
        {
            "level": "Principiante",
            "concept": "cÃ©lula",
            "expected": "ExplicaciÃ³n simple usando lenguaje cotidiano",
        },
        {
            "level": "Intermedio",
            "concept": "homeostasis",
            "expected": "ExplicaciÃ³n con tÃ©rminos tÃ©cnicos moderados",
        },
        {
            "level": "Experto",
            "concept": "transducciÃ³n de seÃ±ales",
            "expected": "ExplicaciÃ³n tÃ©cnica detallada",
        },
    ]

    for example in examples:
        print(f"\nâ€¢ Nivel: {example['level']}")
        print(f"  Concepto: {example['concept']}")
        print(f"  Resultado esperado: {example['expected']}")

    print_section("Conceptos Recomendados para Probar")
    concepts = [
        "cÃ©lula",
        "homeostasis",
        "fotosÃ­ntesis",
        "respiraciÃ³n celular",
        "ADN",
        "ARN",
        "proteÃ­na",
        "enzima",
        "mitocondria",
        "nÃºcleo",
        "membrana",
        "sistema nervioso",
        "neurona",
        "sinapsis",
        "potencial de acciÃ³n",
        "sistema cardiovascular",
        "corazÃ³n",
        "metabolismo",
        "genÃ©tica",
        "cromosoma",
        "mutaciÃ³n",
    ]

    for i, concept in enumerate(concepts):
        if i % 4 == 0:
            print()
        print(f"{concept:20}", end="")
    print()


def main():
    """Main function"""
    if len(sys.argv) > 1:
        mode = sys.argv[1]
    else:
        mode = "quickstart"

    if mode == "quickstart":
        show_quickstart()
    elif mode == "detailed":
        show_detailed_usage()
    elif mode == "troubleshooting":
        show_troubleshooting()
    elif mode == "examples":
        show_examples()
    elif mode == "all":
        show_quickstart()
        show_detailed_usage()
        show_troubleshooting()
        show_examples()
    else:
        print(
            "Uso: python usage_guide.py [quickstart|detailed|troubleshooting|examples|all]"
        )
        sys.exit(1)

    print_header("ðŸŽ¯ Â¡Listo para usar BioLearn-GPT!")
    print(
        """
Para comenzar:
1. python setup.py (si no lo has hecho)
2. python src/main.py --mode all
3. python src/gradio_app.py

Â¡Disfruta generando contenido educativo con IA! ðŸ§¬âœ¨
"""
    )


if __name__ == "__main__":
    main()
